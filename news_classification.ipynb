{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wkyTTrfRsCJr",
    "colab_type": "text"
   },
   "source": [
    "# **Tambah libraries dan setup config untuk menjalankan Google Colab**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "nGT4YIKDsVty",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
    "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
    "!apt-get update -qq 2>&1 > /dev/null\n",
    "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "from oauth2client.client import GoogleCredentials\n",
    "creds = GoogleCredentials.get_application_default()\n",
    "import getpass\n",
    "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
    "vcode = getpass.getpass()\n",
    "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W_toGIyxs6TL",
    "colab_type": "text"
   },
   "source": [
    "# **Mount Google Coud ke  Google Drive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "T48Sicgqyuz7",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "!mkdir -p drive\n",
    "!google-drive-ocamlfuse drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ArCi_eHLtA2a",
    "colab_type": "text"
   },
   "source": [
    "# **Import frameworks dan libraries yang diperlukan**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "vD2Up7n-h2nJ",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    },
    "outputId": "b5ed441b-003c-40ae-b78e-6354d67c6b00"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.utils import resample\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.models import load_model\n",
    "\n",
    "import pickle\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import gensim\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.test.gpu_device_name()\n",
    "\n",
    "import os\n",
    "os.chdir(\"drive/app\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tWSPKlZDtRAQ",
    "colab_type": "text"
   },
   "source": [
    "# **Load dataset, lakukan preprocessing, dan singkronisasi jumlah data.**\n",
    "\n",
    "Contoh dataset seperti gambar di bawah:\n",
    "\n",
    "![alt text](https://preview.ibb.co/f8zC59/Screenshot_from_2018_08_25_06_30_15.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "4Tb2RQ4Ph-Ql",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51.0
    },
    "outputId": "afa205b5-2a23-4980-8d49-29ebd1e6fc6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos: 22826, Neu: 22826, Neg: 22826\n",
      "Total data: 68478\n"
     ]
    }
   ],
   "source": [
    "stopwords = open('data/stopwords.txt', 'r').read().splitlines()\n",
    "\n",
    "def clean_chars(sent):\n",
    "    url_remove = re.sub(r'http\\S+', ' ', sent.lower())\n",
    "    char_remove = re.sub(r'[^a-zA-Z0-9#@]', ' ', url_remove)\n",
    "    char_len = [i for i in char_remove.split() if len(i) > 2]\n",
    "    temp = [i for i in char_len if not i.startswith('#') and not i.startswith('@') and i not in stopwords]\n",
    "    return ' '.join(temp)\n",
    "\n",
    "def sync_data(pos, neu, neg):\n",
    "    dict = {'pos': len(pos), 'neu': len(neu), 'neg': len(neg)}\n",
    "    lowest = min(dict.items(), key=lambda x: x[1])\n",
    "\n",
    "    pos = resample(pos,replace=False, n_samples=lowest[1], random_state=123)\n",
    "    neu = resample(neu,replace=False, n_samples=lowest[1], random_state=123)\n",
    "    neg = resample(neg,replace=False, n_samples=lowest[1], random_state=123)\n",
    "\n",
    "    return pos, neu, neg\n",
    "\n",
    "pos = []\n",
    "neg = []\n",
    "neu = []\n",
    "\n",
    "pos_label = []\n",
    "neg_label = []\n",
    "neu_label = []\n",
    "\n",
    "with open('data/news.json') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "for d in data:\n",
    "  if d['sentiment'] == 'positive':\n",
    "      content = clean_chars(d['texts'])\n",
    "      pos_label.append(d['sentiment'])\n",
    "      pos.append(content)\n",
    "\n",
    "  elif d['sentiment'] == 'negative':\n",
    "      content = clean_chars(d['texts'])\n",
    "      neg_label.append(d['sentiment'])\n",
    "      neg.append(content)\n",
    "\n",
    "  elif d['sentiment'] == 'neutral':\n",
    "      content = clean_chars(d['texts'])\n",
    "      neu_label.append(d['sentiment'])\n",
    "      neu.append(content)\n",
    "      \n",
    "pos, neu, neg = sync_data(pos, neu, neg)\n",
    "\n",
    "print(\"Pos: %s, Neu: %s, Neg: %s\" % (len(pos), len(neu), len(neg)))\n",
    "\n",
    "statuses = pos + neu + neg\n",
    "\n",
    "print(\"Total data: %s\" % len(statuses))\n",
    "\n",
    "pos_label, neu_label, neg_label = sync_data(pos_label, neu_label, neg_label)\n",
    "\n",
    "labels = pos_label + neu_label + neg_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fEpnCzp9uNiD",
    "colab_type": "text"
   },
   "source": [
    "# **Ubah data menjadi embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "aJaDD4wDuJdH",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "max_features = 3000\n",
    "tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
    "tokenizer.fit_on_texts(statuses)\n",
    "\n",
    "X = tokenizer.texts_to_sequences(statuses)\n",
    "X = pad_sequences(X)\n",
    "\n",
    "Y = pd.get_dummies(labels).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D_BX1LGYuW7n",
    "colab_type": "text"
   },
   "source": [
    "# **Split data menjadi data training, testing, valid**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "GadoioUsuoUl",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7uNcwE4LA2tQ",
    "colab_type": "text"
   },
   "source": [
    "# **Create Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "EfXTHEHfiXkU",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "max_features = 3000\n",
    "embed_dim = 128\n",
    "units = 196\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embed_dim, input_length=X.shape[1]))\n",
    "model.add(LSTM(units, dropout=0.2))\n",
    "# model.add(SimpleRNN(units, dropout=0.2))\n",
    "model.add(Dense(3,activation='softmax'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "batch_size = 1000\n",
    "history = model.fit(X_train, y_train, epochs=5, batch_size=batch_size, validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "score, accuracy = model.evaluate(X_val, y_val, batch_size=batch_size, verbose=1)\n",
    "print(\"score: \", score)\n",
    "print(\"accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y13HQEOWEUn2",
    "colab_type": "text"
   },
   "source": [
    "# **Visualisasi**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "GsrTTcoEwlZx",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# df = pd.DataFrame({'epochs':history.epoch, 'accuracy': history.history['acc'], 'validation_accuracy': history.history['val_acc']})\n",
    "# g = sns.pointplot(x=\"epochs\", y=\"accuracy\", data=df, fit_reg=False, color='green')\n",
    "# g = sns.pointplot(x=\"epochs\", y=\"validation_accuracy\", data=df, fit_reg=False, color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ajYXbbW4Xk4X",
    "colab_type": "text"
   },
   "source": [
    "[rnn](https://image.ibb.co/cK9mVz/rnn.png)\n",
    "[rnn-w2v](https://image.ibb.co/bTDDAz/rnn_w2v.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAVKuqsvu3ut",
    "colab_type": "text"
   },
   "source": [
    "# **Save model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "K1HbobyX6VzV",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    },
    "outputId": "a8a6082d-5063-4be5-c938-3c3ed9e8d6f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has created!\n"
     ]
    }
   ],
   "source": [
    "model.save('model/model-rnn.h5')\n",
    "# model.save('model/model-lstm.h5')\n",
    "print(\"Model has created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TAN-vdm-u-3_",
    "colab_type": "text"
   },
   "source": [
    "# **Predict data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "HR6dEg506SKl",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136.0
    },
    "outputId": "10717d36-f85d-4867-80de-d95a8744915f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:  “Ketiga, Riza menyebut permasalahan hukum dan demokrasi yang perlu \n",
      "                 diperbaiki. Ia lalu membandingkan dengan era pemerintahan Susilo \n",
      "                 Bambang Yudyhono yang dinilainya lebih baik. “Sampai hari ini \n",
      "                 banyak masalah hukum. Kedua masalah demokrasi.  Di zaman ini \n",
      "                 reformasi dan dekmokrasi terasa tertinggal. Zaman Pak SBY kita \n",
      "                 mengapresiasi kami mengapresiasi, hukum yang baik,” sebutnya. \n",
      "Sentiment:  negative\n"
     ]
    }
   ],
   "source": [
    "#Neg\n",
    "# input_text = \"\"\"Meski begitu, yang menjadi catatan Nirwono yakni reformasi birokrasi \n",
    "#                 itu belum diiringi dengan penyerapan anggaran maksimal, \n",
    "#                 hanya berkisar antara 45-65 persen selama lima tahun terakhir. \n",
    "#                 Penyerapan anggaran pun lebih banyak dihabiskan untuk operasional \n",
    "#                 kantor dan modal badan usaha milik daerah (BUMD).\"\"\"\n",
    "\n",
    "#Pos\n",
    "# input_text = \"\"\"Di sektor transportasi, lanjut Nirwono, Jokowi berhasil melakukan \n",
    "#                 groundbreaking pembangunan mass rapid transit (MRT). Jokowi bisa \n",
    "#                 mengeksekusi pola makro transportasi terpadu yang sudah disiapkan \n",
    "#                 sejak zaman mantan Gubernur Sutiyoso.\"\"\"\n",
    "\n",
    "#Neg\n",
    "# input_text = \"\"\"“Ketiga, Riza menyebut permasalahan hukum dan demokrasi yang perlu \n",
    "#                  diperbaiki. Ia lalu membandingkan dengan era pemerintahan Susilo \n",
    "#                  Bambang Yudyhono yang dinilainya lebih baik. “Sampai hari ini \n",
    "#                  banyak masalah hukum. Kedua masalah demokrasi.  Di zaman ini \n",
    "#                  reformasi dan dekmokrasi terasa tertinggal. Zaman Pak SBY kita \n",
    "#                  mengapresiasi kami mengapresiasi, hukum yang baik,” sebutnya. \"\"\"\n",
    "\n",
    "#Neg\n",
    "# input_text = \"\"\"Pemerintahan Jokowi gagal memajukan Indonesia\"\"\"\n",
    "\n",
    "text = [clean_chars(input_text)]\n",
    "predicted = tokenizer.texts_to_sequences(text)\n",
    "guess = pad_sequences(predicted, maxlen=X.shape[1])\n",
    "\n",
    "model = load_model('model/model-lstm.h5')\n",
    "# model = load_model('model/model-rnn.h5')\n",
    "prediction = model.predict(guess)\n",
    "polarity = np.argmax(prediction[0])\n",
    "\n",
    "sentiment = ['negative', 'neutral', 'positive']\n",
    "\n",
    "print(\"Text: \",input_text)\n",
    "print(\"Sentiment: \",sentiment[polarity])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rfpbyiAoBRV2",
    "colab_type": "text"
   },
   "source": [
    "# **Create Model (Word2vec)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "Y2du6Y3n2UcI",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "max_features = 3000\n",
    "embed_dim = 128\n",
    "lstm_units = 196\n",
    "\n",
    "def create_embedding_matrix(model):\n",
    "    embedding_matrix = np.zeros((len(model.wv.vocab), embed_dim))\n",
    "    for i in range(len(model.wv.vocab)):\n",
    "        embedding_vector = model.wv[model.wv.index2word[i]]\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix\n",
    "\n",
    "# model = gensim.models.Word2Vec.load(\"w2v/w2v-cbow.bin\")\n",
    "model = gensim.models.Word2Vec.load(\"w2v/w2v-skipgram.bin\")\n",
    "embedding_matrix = create_embedding_matrix(model)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=embedding_matrix.shape[0], output_dim=embedding_matrix.shape[1], weights=[embedding_matrix]))\n",
    "# model.add(LSTM(lstm_units, dropout=0.2))\n",
    "model.add(SimpleRNN(units, dropout=0.2))\n",
    "model.add(Dense(3,activation='softmax'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "batch_size = 1000\n",
    "history = model.fit(X_train, y_train, epochs=5, batch_size=batch_size, validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "score, accuracy = model.evaluate(X_val, y_val, batch_size=batch_size, verbose=1)\n",
    "print(\"score: \", score)\n",
    "print(\"accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rmyvvckTEaQG",
    "colab_type": "text"
   },
   "source": [
    "# **Visualisasi (Word2vec)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "27e4meSR_3eW",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'epochs':history.epoch, 'accuracy': history.history['acc'], 'validation_accuracy': history.history['val_acc']})\n",
    "g = sns.pointplot(x=\"epochs\", y=\"accuracy\", data=df, fit_reg=False, color='green')\n",
    "g = sns.pointplot(x=\"epochs\", y=\"validation_accuracy\", data=df, fit_reg=False, color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6usamRUqYvTw",
    "colab_type": "text"
   },
   "source": [
    "[lstm](https://image.ibb.co/eQv4He/lstm.png)\n",
    "[lstm-w2v](https://image.ibb.co/fGrdce/lstm_w2v.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CWA66wkiBg_Z",
    "colab_type": "text"
   },
   "source": [
    "# **Predict data (Word2vec)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "ARcvHiAaoBnQ",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    },
    "outputId": "4a96d024-7bba-409c-b7a9-1c5007bd6125"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has created!\n"
     ]
    }
   ],
   "source": [
    "# model.save('model/model-rnn-w2v.h5')\n",
    "model.save('model/model-lstm-w2v.h5')\n",
    "print(\"Model has created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "_hWy5Rw0nblW",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "#neg\n",
    "input_text = \"\"\"Meski begitu, yang menjadi catatan Nirwono yakni reformasi birokrasi \n",
    "                itu belum diiringi dengan penyerapan anggaran maksimal, \n",
    "                hanya berkisar antara 45-65 persen selama lima tahun terakhir. \n",
    "                Penyerapan anggaran pun lebih banyak dihabiskan untuk operasional \n",
    "                kantor dan modal badan usaha milik daerah (BUMD).\"\"\"\n",
    "\n",
    "#pos\n",
    "# input_text = \"\"\"Di sektor transportasi, lanjut Nirwono, Jokowi berhasil melakukan \n",
    "#                 groundbreaking pembangunan mass rapid transit (MRT). Jokowi bisa \n",
    "#                 mengeksekusi pola makro transportasi terpadu yang sudah disiapkan \n",
    "#                 sejak zaman mantan Gubernur Sutiyoso.\"\"\"\n",
    "\n",
    "#neg\n",
    "# input_text = \"\"\"“Ketiga, Riza menyebut permasalahan hukum dan demokrasi yang perlu \n",
    "#                  diperbaiki. Ia lalu membandingkan dengan era pemerintahan Susilo \n",
    "#                  Bambang Yudyhono yang dinilainya lebih baik. “Sampai hari ini \n",
    "#                  banyak masalah hukum. Kedua masalah demokrasi.  Di zaman ini \n",
    "#                  reformasi dan dekmokrasi terasa tertinggal. Zaman Pak SBY kita \n",
    "#                  mengapresiasi kami mengapresiasi, hukum yang baik,” sebutnya. \"\"\"\n",
    "\n",
    "#neg\n",
    "# input_text = \"\"\"Pemerintahan Jokowi gagal memajukan Indonesia\"\"\"\n",
    "\n",
    "text = [clean_chars(input_text)]\n",
    "predicted = tokenizer.texts_to_sequences(text)\n",
    "guess = pad_sequences(predicted, maxlen=X.shape[1])\n",
    "\n",
    "# model = load_model('model/model-rnn-w2v.h5')\n",
    "model = load_model('model/model-lstm-w2v.h5')\n",
    "prediction = model.predict(guess)\n",
    "polarity = np.argmax(prediction[0])\n",
    "\n",
    "sentiment = ['negative', 'neutral', 'positive']\n",
    "\n",
    "print(\"Text: \",input_text)\n",
    "print(\"Sentiment: \",sentiment[polarity])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rsasTwVcEdt9",
    "colab_type": "text"
   },
   "source": [
    "# **Perbandingan hasil antara RNN (atas) dan RNN yang menggunakan word2vec (bawah)**\n",
    "![rnn](https://image.ibb.co/cK9mVz/rnn.png)\n",
    "![rnn-w2v](https://image.ibb.co/bTDDAz/rnn_w2v.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-xomdM8sGp4d",
    "colab_type": "text"
   },
   "source": [
    "# **Perbandingan hasil antara LSTM LSTM yang menggunakan word2vec (bawah)**\n",
    "\n",
    "![lstm](https://image.ibb.co/eQv4He/lstm.png)\n",
    "![lstm-w2v](https://image.ibb.co/fGrdce/lstm_w2v.png)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "news-classification.ipynb",
   "version": "0.3.2",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}